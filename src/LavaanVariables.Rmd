---
title: "At3modelling"
author: "Alex Brooks"
date: "10/12/2018"
output: html_document
---
## SEM MODELLING ON VACCINATION DATA
```{r setup, include=FALSE}
library(lavaan)
library(semPlot)
options (scipen = 999)
library(dplyr)
library(caret)
library(corrplot)
library(glmnet)
library(gapminder)
library(openintro)
library(ggplot2)
library(Amelia)
library(missMDA)
```

 

```{r}
#read in the data
Data <-read.csv('../cleaned_data/all_immunisation_seifa.csv')
str(Data)
```

##try to assess feature importance, using the traditional examindation of the dataset in 'https://github.com/jeromyanglim/lavaan-examples/blob/master/path-analysis/path-analysis.rmd'
What is the data
three geographic variables - can these be predictors? PHN number, Electorate, Postcode and SA3 in a separate datasets
one dependent variable - vaccine trust (or is this the mediator variable)
- Choose one SEIFA score, not all
- Choose political score
- Choose mean tax
Create density plots of key variables
```{r}

# Create density plots of key variables
Data %>%
  ggplot(aes(pc_immun_class)) +
  geom_density()

```

```{r}
#political score density plot
Data %>%
  ggplot(aes(political_score)) +
  geom_density()
```
```{r}
Data %>%
  ggplot(aes(mean_tax_000s)) +
  geom_density()
```
```{r}
Data %>%
  ggplot(aes(caution)) +
  geom_density()
```
```{r}
Data %>%
  ggplot(aes(total_tax)) +
  geom_density()
```

## What shall we do with 0 pc immun class? Remove them

With missing data - this data is NOT PUBLISHED - so it's not missing at random. Dr Erin M Buchanan says you can exclude the extraneous variable and use something different

MEAN SUBSTITUTION
There are ways to estimate methods to fill in missing data - mean substitution fills in the average for that column by year. That's the default in SPSS, and it's a conservative approach as it doesn't change average scores but will lower the variance. Because it reduces variance, that creates more of a Type 1 error. That's why most people like to limit imputation to 5%. It can make a p value slip.

MULTIPLE IMPUTATION
this is considered the best way to do this, in R it's easier using MICE. You run multiple times and look at the data across and down. You can't replace categorical variables or demographics - either leave them out or pairwise eliminate them. Categorical and demographic variables should not be eliminated by leaving them out or doing pairwise elimination

IMPUTE USING PCA
Authors Josse and Husson propose multiple correspondence analysis for categorical variables, factorial analysis on mixed data for both continuous and categorical variables, and multiple factor analysis for multi-table data. Furthermore, missMDA can be used to perform single imputation to complete data involving continuous, categorical and mixed variables. A multiple imputation method is also available. In the principal component analysis framework, variability across different imputations is represented by confidence areas around the row and column positions on the graphical outputs. This allows assessment of the credibility of results obtained from incomplete data sets

Have to estimate the PCA variations first.
 

```{r}
#latent variable i s pc immun in this experiment
imm.model <- 'pc_immun_class =~ mean_tax_000s+IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
imm.fit <- cfa(model=imm.model,
                  data = Data)
summary(imm.fit, standardized = TRUE, fit.measures = TRUE)

```
```{r}
#plot it
lavInspect(imm.fit, what="estimates")
```
```{r}
semPaths(imm.fit,  what = "stand", rotation = 4)
```
```{r}
semCors(imm.fit, include="difference")
```

```{r}
#plot of model 1
semPaths(object = imm.fit,
          whatLabels = "std", 
          edge.label.cex = 1.5, 
          layout = "tree", rotation = 4)
```
```{r}
modificationindices(imm.fit, sort = TRUE)
```
```{r}
imm.model <- 'pc_immun_class =~ mean_tax_000s+IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'

#let's see if sentiment can be created on its own
imm.model2 <- 'sentiment =~ pc_immun_clas s+ mean_tax_000s+age+year+political_score+ IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE+PHN_number'
imm.fit2 <- cfa(model=imm.model2,
                  data = Data)
summary(imm.fit2, standardized = TRUE, fit.measures = TRUE)

```

```{r}
#plot of model 2
semPaths(object = imm.fit2,
          whatLabels = "std", 
          edge.label.cex = 1.5, 
          layout = "tree", rotation = 4)
```

#Not perfect, but OK for now
```{r}
#try two factor
twofactorimm.model <- 'socio =~ age + year+ pc_immun_class + postcode + IRSAD_URP
    sentiment =~ political_score + mean_tax_000s + IER_SCORE
socio~~sentiment'
twofactorimm.fit <- cfa(model = twofactorimm.model,
                     data = Data)
summary(twofactorimm.fit, standardized = TRUE, fit.measures = TRUE)
#covariance warning 
```
```{r}
semPaths(object = twofactorimm.model,
          whatLabels = "std", 
          edge.label.cex = 1.5, 
          layout = "tree", rotation = 4)
```

#Not perfect, but OK for now
```{r}
#try three factor
threefactorimm.model <- 'immun =~ postcode + PHN_number + pc_immun_class + year + age 
    sentiment =~ political_score + mean_tax_000s + pc_immun_class
socio =~ IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
threefactorimm.fit <- cfa(model = threefactorimm.model,
                     data = Data)
summary(threefactorimm.fit, standardized = TRUE, fit.measures = TRUE)
 
```

```{r}
semPaths(object = threefactorimm.model,
          whatLabels = "std", 
          edge.label.cex = 1.5, 
          layout = "tree", rotation = 4)
```
###NEed to redo datacamp to check the
two factor models can have a correlation between latent variables - lavaan does this by default - latent variables thought to predict the scores on manifest variables. We can use latent variables to predict each other.

EG
twofactor.model <- 'visual =~ x1 + x2 + x3
    speed =~ x7 + x8 + x9'
twofactor.fit <- cfa(model = twofactor.model,
                     data = HolzingerSwineford1939)
summary(twofactor.fit, standardized = TRUE, fit.measures = TRUE)
OUTPUT
Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.777    0.667
    x2                0.690    0.124    5.585    0.000    0.536    0.456
    x3                0.985    0.160    6.157    0.000    0.766    0.678
  speed =~                                                              
    x7                1.000                               0.622    0.572
    x8                1.204    0.170    7.090    0.000    0.749    0.741
    x9                1.052    0.147    7.142    0.000    0.654    0.649
  Covariances: THE AMOUNT WHICH TWO VARIABLES CHANGE TOGETHER
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  visual ~~                                                             
    speed             0.223    0.052    4.290    0.000    0.460    0.460
    
    Visual and speed overlap by 20% 
    single tilde represents regression, double tilde represents correlation
    
    latent variables individually predict manifest variables
    But the models are estimated with the covarying relationship between the predictor variables
    
    ASSESSING MODIFICATION INDICES can improve your model
    
    CFI and TLI are below the desired criterion of 0.9. Badness of fit with RMSEA is higher than a base criteria of 0.10 and SRMR.
    
    Examine the loadings and variances to determine if manifest variables aren't related to latent variables or having improbable 
    
    Each manifest variable is related to the latent variable if the variance is over 0.3
    
    variances shouldn't match the real variance - but use the var function to get a range of the variance. Estimated variances are large in comparison to the data when something goes wrong.
    
    Modification indices - explore these as a second step. These indicate the oimrpovement on a model if the suggested stimate is added to the model
    US modification indices with model fit as the main argument - srto = TRUE will show you the biggest changes on top (which is good for complex models) - LHS and 
    
    modificationindices(twofactor.fit, sort = TRUE)
    lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox
34     x7 ~~  x8 35.521  0.624   0.624    0.568    0.568
18 visual =~  x9 35.521  0.659   0.512    0.508    0.508
36     x8 ~~  x9 19.041 -0.527  -0.527   -0.517   -0.517
16 visual =~  x7 19.041 -0.503  -0.391   -0.359   -0.359
26     x1 ~~  x9 11.428  0.177   0.177    0.151    0.151
28     x2 ~~  x7  9.096 -0.184  -0.184   -0.144   -0.144
17 visual =~  x8  3.557 -0.227  -0.176   -0.175   -0.175
35     x7 ~~  x9  3.557 -0.164  -0.164   -0.150   -0.150
24     x1 ~~  x7  3.022 -0.100  -0.100   -0.079   -0.079
19  speed =~  x1  2.815  0.309   0.192    0.165    0.165
27     x2 ~~  x3  2.815  0.174   0.174    0.131    0.131
33     x3 ~~  x9  2.793  0.085   0.085    0.074    0.074
23     x1 ~~  x3  2.632 -0.298  -0.298   -0.227   -0.227

MI is modification index - this is the amount he chi square index will decrease when added to the model. Last 4 columns indicate extpected parameter change. This table will determine whether to add estimates to a model - add it one at a time and select them for theoretical implications.

To update, you add a line as a new path in the model fit. Then you improve the fit indices.