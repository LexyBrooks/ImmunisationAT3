---
title: "LavaanTrial"
author: "Alex Brooks"
date: "10/9/2018"
output: html_document
---
#Testing SEM modelling using Lavaan package
Try using the immunization with everything including taxation dataset to play with.
Try to do exploratory factor analysis, when you have a dataset in shape
```{r setup, include=FALSE}
library(lavaan)
library(tidyverse)
library(dplyr)
library(corrplot)
options(scipen = 999)
```

## Manifest and Latent Variables

Abstract variables are latent - and not measured - and represented by a circle, while Manifest variables are concrete and represented by a square. You need 1 latent variable to 3 manifest variables.

Name your model - you need to specify it and fit it, so make the naming flexible

=~ is the symbol that represents the direction of the equation.

Typical form is 
visual.model <- 'visual.latent =~ manifest.variable1 + manifest.variable2 + manifest.variable3 ...'

A one factor model is measured by degrees of freedom.
Degrees of freedom are the possible values minus the estimated values.
The possible values = manifest variables*(manifest variables +1)/2

The model works when you have enough manifest variables plus you have degrees of freedom of zero.

Scaling can help you understand. Set a manifest variable to 1, name the model and use fit from specific name.
```{r}
Data <-read.csv('../cleaned_data/all_immunisation_seifa.csv')
str(Data)
#think about transforming federal electorates by left and right scores?
```


```{r, fig.width=12, fig.height=10}
#check correlation between variables on Data that is numeric
#remove factors to run correlation plots on cor(Data)
#don't want ID- keep 2 - sex, education marriage or age
removed <- Data[,-c(2,5,8,50)]  
corplot <-cor(removed)
corrplot(corplot, method="pie") 
```




```{r}
#Select the manifest variables
# 
#Latent variable is immun_class - let's try a single factor model
#latent variable i s pc immun in this experiment and this is a bad model for using all SEIFA scores
imm.model <- 'pc_immun_class =~ mean_tax_000s+IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE+PHN_number'
imm.fit <- cfa(model=imm.model,
                  data = Data)
summary(imm.fit, standardized = TRUE, fit.measures = TRUE)
  
```
#this first model is possibly the best fit
Let's try some different variables and see how it comes together
```{r}
imm.model2 <- 'pc_immun_class =~ mean_tax_000s + PHN_number + age
socio =~ IRSD_SCORE + postcode + IRSAD_SCORE'
imm.fit2 <- cfa(model=imm.model2,
                  data = Data)
summary(imm.fit2, standardized = TRUE, fit.measures = TRUE)
  
```
```{r}
imm.model3 <- 'pc_immun_class =~ IRSD_MAXS+IRSD_MINS+IRSAD_MAXS+IRSAD_MINS+IER_MAXS+IER_MINS+IEO_MAXS+IEO_MINS
postcode=~ PHN_number+age+IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
imm.fit3 <- cfa(model=imm.model3,
                  data = Data)
summary(imm.fit3, standardized = TRUE, fit.measures = TRUE)
  
```
```{r}
imm.model4 <- 'pc_immun_class =~ mean_tax_000s + IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
imm.fit4 <- cfa(model=imm.model4,
                  data = Data)
summary(imm.fit4, standardized = TRUE, fit.measures = TRUE)
#v bad
```

```{r}
imm.model5 <- 'pc_immun_class =~ total_tax+mean_tax+ IRSD_MAXS+IRSD_MINS+IRSAD_MAXS+IRSAD_MINS+IER_MAXS+IER_MINS+IEO_MAXS+IEO_MINS+ IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
imm.fit5 <- cfa(model=imm.model5,
                  data = Data)
summary(imm.fit5, standardized = TRUE, fit.measures = TRUE)
```
```{r}
#bring in new data
newdata <- read.csv('../cleaned_data/all_immunisation_elecscore.csv')
str(newdata)
```
##let's try a model with the elec scores against the latent variable of pc_immun_class - will have to include years in some way too??? TALK TO ANT ABOUT YEARS???

```{r}
elec.model <- 'pc_immun_class =~ year+X2016_score+X2015_score+X2014_score+X2013_score+X2012_score+X2011_score'
elec.fit <- cfa(model=elec.model,
                  data = newdata)
summary(elec.fit, standardized = TRUE, fit.measures = TRUE)
  #cos the election scores have a linear relationship, the model can't happen
```
```{r}
#try it just for 2016
elec.model2 <- 'pc_immun_class =~mean_tax+X2016_score+year+ IRSD_MAXS+IRSD_MINS+IRSAD_MAXS+IRSAD_MINS+IER_MAXS+IER_MINS+IEO_MAXS+IEO_MINS+ IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE'
elec.fit2 <- cfa(model=elec.model2,
                  data = newdata)
summary(elec.fit2, standardized = TRUE, fit.measures = TRUE)
  
```


```{r}
elec.model2 <- 'pc_immun_class =~ _score+IRSD_SCORE+IRSAD_SCORE+IER_SCORE+IEO_SCORE+IRSD_URP+IRSAD_URP+IER_URP+IEO_URP
```

##Selecting variables for SEM 
I need to transform mean_tax in some way to be relative to the other numbers??? Not sure how to do that

Also wondering
You can use confirmatory factor analysis
https://www.youtube.com/watch?v=1yyhdgZ6pYE

Estimate columns gives you the factor - lavaan constrains the first manifest variable, but if you need to constrain the others

The first variable is constrained to equal 1

COVARIANCES - between latent variables, lavaan does this by default

lavaan uses unit loading default on latent variables and takes the first variale to equal one unless you tell it otherwise. If you want to use a different variable then you pre-multiply first variable NA*x1 

SEM modelling in Lavaan
Step one: specify a model that might only be conceptual
Step two: R estimates the parameters
Step three: request the results
There are modifications that can be made to commands you put in. 

Regression - regress the left hand on to the right hand variable with a tilde

When R estimates parameters, you can use sem(fit.model, data = whatever) and you will only see basic results with summary command. Lavaan doesn't give all the results it has stored, estimates are unstandardized coefficients, so add standardized = TRUE is you want me, and add fit.measures = T, if you want r squared you use rse=TRUE too.

You can also specify indirect, direct and total effects on variables.
indirect effect = a*b *a path times p path) have to use colon and equal

#MUltiple variables at once are multiple lines and latent coompared to indicator/manifest variables

IRSAD_SCORE, IRSD_SCORE, mean_tax, electorate, PHN number, pc_immun_class, year, age, postcode?
Think about transforming electorate into LEFT for Greens and Independents and Labor who are RED and RIGHT for Libs, Nats, Conservative Independents - making it numeric

My latent variable could be: vaccine trust as measured by Google search demand?

 
##Experiment & hypothesis
Manifest variables are - PHN_code, Index.type, Time, Maximum.score.for
Standardized loadings - loadings show the strength of the relationship of the manifest variables - standardized loadings often easier to interpret.
includ e- standardised = TRUE - in the summary to get these standardized loadings, which are easier

std.lv - would be the solution is you set it to the latent variable. 

People often use a criteria of 0.3 as an acceptable loading.

Model  fit like CFI and TLI work (want them to be close to1)
Badness of fit like RMSEA and SRMR can be used (want them to be 0 - Davd A Kenny website pn measuring model fit)

summary(visual.fit, standardized = TRUE, fit.measures = TRUE)
Use thisc ommand to see fit

Models can be single factor or multi factor


```{r pressure, echo=FALSE}
plot(pressure)
```

#Multiple latent variables and relationships

visual.model (1 latent variable and 6 manifest variables) - combining visual skills and speed skills

Separate the model into two smaller models with 3 manifest variables each - first the models won't be identified and will have zero degrees of freedom - identification is tied to the numbers of variables you estimate

We want to fix models to have one degree of freedom, and you do this by specifying constraints. Set parameters to be equal and only calculate one number instead of several. x2 and x3 can have the same loading value by typing a* - the first variable is the marker variable used to scale the model.

EG
visual.model <- 'visual =~ x1 + a*x2 + a*x3'
data = HolzingerSwineford1939)    
summary(visual.fit, standardized = TRUE, fit.measures = TRUE)
OUTPUT:
  Number of observations                           301

  Estimator                                         ML
  Minimum Function Test Statistic                3.783
  Degrees of freedom                                 1
  P-value (Chi-square)                           0.052

                          ___

Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.745    0.639
    x2         (a)    0.910    0.142    6.397    0.000    0.678    0.562
    x3         (a)    0.910    0.142    6.397    0.000    0.678    0.614
    

Z score on latent and manifest variables
Splitting into two separate models means you don't capture the relationship between the two variables - specifying a multifactor model is better

twofactor.model <- 'visual =~ x1 + x2 + x3 
    speed =~ x7 + x8 + x9'
    summary(twofactor.fit, standardized = TRUE, fit.measures = TRUE)
    
    Analyze the model with CFA and summary functions
    
    OUTPUT
    Number of observations                           301

  Estimator                                         ML
  Minimum Function Test Statistic               47.413
  Degrees of freedom                                 8
  P-value (Chi-square)                           0.000
    
    Both latent variables and 6 manifeset variables.
  
  
  #lavaan by default makes manifest variables covariance checks
  
  #Model structures
  Models can check co variances between multiple latent variables too.
  
  twofactor.model <- 'visual =~ x1 + x2 + x3
    speed =~ x7 + x8 + x9'
twofactor.fit <- cfa(model = twofactor.model,
                     data = HolzingerSwineford1939)
summary(twofactor.fit, standardized = TRUE, fit.measures = TRUE)

OUTPUT -
Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  visual =~                                                             
    x1                1.000                               0.777    0.667
    x2                0.690    0.124    5.585    0.000    0.536    0.456
    x3                0.985    0.160    6.157    0.000    0.766    0.678
  speed =~                                                              
    x7                1.000                               0.622    0.572
    x8                1.204    0.170    7.090    0.000    0.749    0.741
    x9                1.052    0.147    7.142    0.000    0.654    0.649
    NEW SECTION HAS CO-VARIANCE (the amount two variables change together but hard to interpret because the scale is not standardized - this output shows it standardized. This shows 20% which is correlation squared - if it gets too close to one, the model won't run.
    Covariances:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  visual ~~                                                             
    speed             0.223    0.052    4.290    0.000    0.460    0.460
    
    
    DOUBLE TILDE between visual and speed is how you specify - you can turn off the covariance by setting the estimate to zero.
    
    These move to three factor models. The two - or more - latent variables are then called endogenous variables and they will be automatically correlated - you can set the vorrelations to 0 by using ~~ in model specification.
    
    MODIFICATION INDICES
    CFi and TLI - desired criterion of .9. Where RMSE is higher than.10 and SMR is OK
    
    Examine loading and variances to check if manifest variables have improbable error variables.
    
    Is each loading over 0.3?
    When something goes wrong with the variable, you can explore modification indices - the improvement on a model if a suggested estimate is added.
    
    modficiationindices(twofactor.fit, sort =TRUE) - sort will show you lhs - left hand side
    rhs - right hand side
    op - operator (the correlation with double tilder)
    mi = chi square value - the amount chi square will decrease
    OUTPUT EG
    lhs op rhs     mi    epc sepc.lv sepc.all sepc.nox
34     x7 ~~  x8 35.521  0.624   0.624    0.568    0.568
18 visual =~  x9 35.521  0.659   0.512    0.508    0.508
36     x8 ~~  x9 19.041 -0.527  -0.527   -0.517   -0.517
16 visual =~  x7 19.041 -0.503  -0.391   -0.359   -0.359
26     x1 ~~  x9 11.428  0.177   0.177    0.151    0.151
28     x2 ~~  x7  9.096 -0.184  -0.184   -0.144   -0.144
17 visual =~  x8  3.557 -0.227  -0.176   -0.175   -0.175
35     x7 ~~  x9  3.557 -0.164  -0.164   -0.150   -0.150
24     x1 ~~  x7  3.022 -0.100  -0.100   -0.079   -0.079
19  speed =~  x1  2.815  0.309   0.192    0.165    0.165
27     x2 ~~  x3  2.815  0.174   0.174    0.131    0.131
33     x3 ~~  x9  2.793  0.085   0.085    0.074    0.074
23     x1 ~~  x3  2.632 -0.298  -0.298   -0.227   -0.227
                            _ _ _
                            Use this table, add parameters one at a time and select for theoretical 
                            
                            Just add new line in model EG
                            DataCampStructural Equation Modeling with lavaan in RUpdating the Model
34     x7 ~~  x8 35.521  0.624   0.624    0.568    0.568

You need to use the dataframe name to compare the variance of original manifest variable to estimated variance var(DF$column). You can see that your variance from the model (0.199) is very similar to the real variance (0.201) which indicates our model does not have variance issues. 

TWO WAYS TO COMPARE MODELS to check fit

Create and CFA on two models with diff names
then use ANOVA to compare the two models anova(twofactor.fit, twofactor.fit1)
OUTPUT - aic and BIC
Chi Square Difference Test

               Df    AIC    BIC  Chisq Chisq diff Df diff    Pr(>Chisq)    
twofactor.fit1  7 5150.5 5202.4 14.753                                     
twofactor.fit   8 5181.2 5229.4 47.413     32.661       1 0.00000001097 ***

Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Chi square difference test subtracts two chi square values - Chi square values must increase to be significant at p < .05

Only useful for models with the same variables

An additional way to compare models is FIT INDICES - especially for non-nested models
Fitmeasures function can show you more
EG OUTPUT
fitmeasures(twofactor.fit)
               npar                fmin               chisq 
             13.000               0.079              47.413 
                 df              pvalue      baseline.chisq 
              8.000               0.000             341.721 
        baseline.df     baseline.pvalue                 cfi 
             15.000               0.000               0.879 
                tli                nnfi                 rfi 
              0.774               0.774               0.740 
                nfi                pnfi                 ifi 
              0.861               0.459               0.882 
                rni                logl   unrestricted.logl 
              0.879           -2577.584           -2553.877 
                aic                 bic              ntotal 
           5181.168            5229.361             301.000 
               bic2               rmsea      rmsea.ci.lower 
           5188.132               0.128               0.094 
     rmsea.ci.upper        rmsea.pvalue                 rmr 
              0.164               0.000               0.096
                                _ _ _
Fit Index Comparison Compare fit indices for non-nested models Get more fit indices with fitmeasures() fitmeasures(twofactor.fit) npar fmin chisq 1
AIC - lower values are better, even if nagative
ECVI is the likelihood this model will replicate - lower values are better
To get just these, you can concatenate the list of your fit indices

fitmeasures(twofactor.fit1, c("aic", "ecvi"))
     aic     ecvi 
5150.508    0.142
   OUTPUT EG: Chi Square Difference Test

         Df   AIC   BIC  Chisq Chisq diff Df diff Pr(>Chisq)    
epi.fit1 50 46220 46390 332.89                                  
epi.fit  51 46396 46560 510.40     177.51       1  < 2.2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

COMMON ERRORS IN MULTI FACTOR LATENT VARIABLE MODELS
WHen estimation of correlation is over the value of 1 - or out of bounds - can occur when negative variances are estimated. Negative variances shouldn't happen because of squaring. NEgative variances occur in the error terms

POSITIVE DEFINITE ERROS indicate one variable is a combination of the other variables. 
Check for warnings after cfa function, as summary does not display them.

check the summary in covariance

You can combine latent variables. EG
#original model
epi.model <- 'extraversion =~ V3 + V7 + V11 + V15
    neuroticism =~ V1 + V5 + V9 + V13
    lying =~ V4 + V8 + V12 + V16'
    #respecify the model
epi.model2 <- 'extraversion =~ V3 + V7 + V11 + V15
    neuroticism_lie =~ V1 + V5 + V9 + V13 + V4 + V8 + V12 + V16'

epi.fit2 <- cfa(model = epi.model2, data = epi)
summary(epi.fit2, standardized = T, fit.measures = T)

semPlot and semPaths() - the graphical representation
#load libraries
library(lavaan)
library(semPlot)
#run your model
twofactor.model <- 'text =~ x4 + x5 + x6
    speed =~ x7 + x8 + x9'
twofactor.fit <- cfa(model = twofactor.model, 
                     data = HolzingerSwineford1939)
                     
semPaths creates the diagrams
#basic diagram                     
semPaths(object = twofactor.fit)
semPaths(object = twofactor.fit,
         whatLabels = "std", 
         edge.label.cex = 1)
#whatLabels can also be "par"
what labels is the text to depict on single and double headed arrow lines "par" is undstandardised. Standardised is 'std" and cex = 1 to increase font size.

Layout and rotation options - tree is default, circle, spring and default - the best options depend on your model.
Rotation is useful if you have manifest variables and only happens with tree. 
What argument colours parameter arrows based on the strength of your estimates. edge.colour changes the colour"

This allows you to diagram your fitted sem model
saved fitte model object. Double headed arrows indicate variances, and between latents are co-variants.
EDITING PICTURE
semPaths(object = twofactor.fit,
         whatLabels = "std", 
         edge.label.cex = 1)
#whatLabels can also be "par" (this is on lines)
LAYOUT
semPaths(object = twofactor.fit,
          whatLabels = "std", 
          edge.label.cex = 1, 
          layout = "circle")
#layout options are tree, circle, spring, tree2, circle2
ROTATION (only for tree)
semPaths(object = twofactor.fit,
          whatLabels = "std", 
          edge.label.cex = 1, 
          layout = "tree", rotation = 2)
#layout options are tree, circle, spring, tree2, circle2
#rotation options are 1, 2, 3, 4 for tree layouts
COLOR VIZ

EG OF THREE FACTOR MODEL
semPaths(object = wais.fit, layout = "tree", rotation = 1,
          whatLabels = "std", edge.label.cex = 1,
          what = "std", edge.color = "black")
          
          SUMMARY for WAIS subscales
          summary(wais.fit, standardized = TRUE, fit.measures = TRUE)
          Latent Variables:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
  verbalcomp =~                                                         
    vocab             1.000                               6.281    0.879
    simil             0.296    0.031    9.483    0.000    1.861    0.581
    inform            0.449    0.043   10.481    0.000    2.822    0.644
    compreh           0.315    0.035    8.999    0.000    1.981    0.552
  workingmemory =~                                                      
    arith             1.000                               2.528    0.844
    digspan           0.881    0.152    5.786    0.000    2.227    0.565
    lnseq             0.205    0.107    1.920    0.055    0.518    0.129
  perceptorg =~                                                         
    piccomp           1.000                               1.517    0.650
    block             3.739    0.390    9.583    0.000    5.672    0.735
    matrixreason      0.832    0.117    7.099    0.000    1.262    0.493
    digsym            1.603    0.507    3.160    0.002    2.431    0.207
    symbolsearch      1.880    0.204    9.236    0.000    2.852    0.690
    
    GOOD TO CHECK VARIANCES - they can indicate problems
    Variances:
                   Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all
   .vocab            11.577    2.651    4.367    0.000   11.577    0.227
   .simil             6.787    0.620   10.950    0.000    6.787    0.662
   .inform           11.218    1.085   10.342    0.000   11.218    0.585
   .compreh           8.962    0.803   11.155    0.000    8.962    0.696
   .arith             2.571    1.014    2.535    0.011    2.571    0.287
   .digspan          10.590    1.161    9.121    0.000   10.590    0.681
   .lnseq            15.807    1.297   12.183    0.000   15.807    0.983
   .piccomp           3.138    0.317    9.913    0.000    3.138    0.577
   .block            27.343    3.226    8.476    0.000   27.343    0.459
   .matrixreason      4.960    0.441   11.243    0.000    4.960    0.757
   .digsym          132.291   10.925   12.109    0.000  132.291    0.957
   .symbolsearch      8.936    0.957    9.333    0.000    8.936    0.524
    verbalcomp       39.455    4.754    8.299    0.000    1.000    1.000
    workingmemory     6.388    1.215    5.259    0.000    1.000    1.000
    perceptorg        2.301    0.408    5.646    0.000    1.000    1.000
    
    USE THE VAR FUNCTION TO CHECK HIGH VARIANCES - These can just be variables with high variance
    var(IQdata$digsym)
[1] 138.665
MODIFICATION INDICES OUTPUT - may have correlated error terms
modificationindices(wais.fit, sort = TRUE)
              lhs op          rhs     mi     epc sepc.lv sepc.all sepc.nox
66          simil ~~       inform 35.879  -3.757  -3.757   -0.268   -0.268
56          vocab ~~       inform 28.377   9.783   9.783    0.313    0.313
48     perceptorg =~        vocab 21.865  -2.077  -3.151   -0.441   -0.441
115         block ~~ matrixreason 16.209  -3.622  -3.622   -0.183   -0.183
96          arith ~~        block 15.061   3.679   3.679    0.159    0.159
117         block ~~ symbolsearch 13.144   5.725   5.725    0.180    0.180
47  workingmemory =~ symbolsearch 12.272  -0.467  -1.181   -0.286   -0.286
81         inform ~~        block 12.269   4.358   4.358    0.129    0.129
64          vocab ~~       digsym 11.578 -11.261 -11.261   -0.134   -0.134
40  workingmemory =~        simil 11.383   0.278   0.703    0.220    0.220
72          simil ~~        block 10.605  -3.084  -3.084   -0.125   -0.125
45  workingmemory =~ matrixreason  9.685   0.267   0.675    0.264    0.264
    
Edge.colour changes the colour of the shading
semPaths(object = twofactor.fit,
         whatLabels = "std", 
         edge.label.cex = 1, 
         layout = "tree", rotation = 2,
         
         https://assets.datacamp.com/production/repositories/1919/datasets/f767ab580a91a39847d12c6179439e0ad5fdbd9d/DC%20C4.1.jpg (four factor model of intelligence)
         
         Look for Heywood cases when optimising your models
         what = "std", edge.color = "purple")
#what options include par and std

SUMMARY

Model Syntax
=~ to define latent variables
~~ to define covariance and correlation
~ to define direct prediction

Three model types
One-Factor Models
Multifactor Models
Hierarchical Models


